{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## HuBMAP-22 Challenge\n",
        "\n",
        "This is my notebook with the training and submitting for the HuBMAP-22 Challenge.\n"
      ],
      "metadata": {
        "id": "6v22Y8t6pqbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requirements\n",
        "Installing the required packages:"
      ],
      "metadata": {
        "id": "zbKUqAG7pyRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -qq git+https://github.com/qubvel/segmentation_models.pytorch\n",
        "!pip install timm==0.4.12\n",
        "!pip install einops"
      ],
      "metadata": {
        "id": "b0KwsgMapx7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading libraries and utilities:"
      ],
      "metadata": {
        "id": "ZSWc9B269Ow-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "from sklearn.model_selection import KFold\n",
        "import segmentation_models_pytorch as smp\n",
        "import tifffile\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from coat import *\n",
        "from daformer import *\n",
        "from utils import seed_everything, make_fold, get_mask"
      ],
      "metadata": {
        "id": "nHcMI6CTxO5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuration\n",
        "\n",
        "We define all the parameters for the notebook"
      ],
      "metadata": {
        "id": "1uHjzl6V-pQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "IMG_SIZE = 768\n",
        "BATCH_SIZE = 1\n",
        "ACCUMULATION = 24\n",
        "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "EPOCHS = 200\n",
        "NUM_WORKERS = 4\n",
        "TRAIN_IMG = 'hubmap-organ-segmentation/train_images/'\n",
        "TEST_IMG = 'hubmap-organ-segmentation/test_images/'\n",
        "val_fold = 0\n",
        "num_fold = 5\n",
        "\n",
        "seed_everything(SEED)"
      ],
      "metadata": {
        "id": "81BbZ6qg-gU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataframes:"
      ],
      "metadata": {
        "id": "_SwQg3LPAFfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('hubmap-organ-segmentation/train.csv')\n",
        "test_df = pd.read_csv('hubmap-organ-segmentation/test.csv')"
      ],
      "metadata": {
        "id": "MQYvh1bpAFJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = make_fold(num_fold=num_fold, val_fold=val_fold, df=train)"
      ],
      "metadata": {
        "id": "GjKAqpZzBGFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HuBMAPData(Dataset):\n",
        "    def __init__(self, transform=None, df=train_df):\n",
        "        self.transform = transform\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        temp = self.df.iloc[index]\n",
        "        id = temp['id']\n",
        "        organ = temp['organ']\n",
        "\n",
        "        PATH = TRAIN_IMG\n",
        "        image = tifffile.imread(PATH+str(id)+'.tiff')\n",
        "        mask = get_mask(id, self.df)\n",
        "        mask[mask == 255.0] = 1.0\n",
        "\n",
        "        if self.transform is not None:\n",
        "            augmentations = self.transform(image=image, mask=mask)\n",
        "            image = augmentations[\"image\"]\n",
        "            mask = augmentations[\"mask\"]\n",
        "            mask = mask.float()\n",
        "\n",
        "        return image, mask, organ"
      ],
      "metadata": {
        "id": "OW5T0sLOBWDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = A.Compose(\n",
        "      [\n",
        "        A.Resize(height=IMG_SIZE, width=IMG_SIZE),\n",
        "        A.Rotate(limit=35, p=0.8),\n",
        "        A.OneOf([\n",
        "            A.HorizontalFlip(p=0.6),\n",
        "            A.VerticalFlip(p=0.6),\n",
        "            A.RandomRotate90(p=0.6)\n",
        "        ], p=1.0),\n",
        "        A.OneOf([\n",
        "            A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n",
        "            A.GridDistortion(p=0.5),\n",
        "            A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=0.5) \n",
        "        ], p=0.8),\n",
        "        A.ChannelShuffle(p=0.4),\n",
        "        A.GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, always_apply=False, p=0.4),\n",
        "        A.OneOf([\n",
        "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, always_apply=False, p=0.75),\n",
        "            A.RandomBrightnessContrast(p=0.7),\n",
        "            A.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.25, p=0.75)\n",
        "        ], p=0.9),\n",
        "        A.RandomGamma(p=0.6),\n",
        "        ToTensorV2(transpose_mask=True),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "val_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=IMG_SIZE, width=IMG_SIZE),\n",
        "        ToTensorV2(transpose_mask=True),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "elZ1Bdd_Bizv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = HuBMAPData(transform=train_transform, df=train_df)\n",
        "val_dataset = HuBMAPData(transform=val_transform, df=val_df)\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
        "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "sru3YutIBnNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CoaT \n",
        "\n",
        "Model architecture\n",
        "\n"
      ],
      "metadata": {
        "id": "zTQHrR0T_F5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RGB(nn.Module):\n",
        "    IMAGE_RGB_MEAN = [0.485, 0.456, 0.406]  \n",
        "    IMAGE_RGB_STD = [0.229, 0.224, 0.225] \n",
        "    \n",
        "    def __init__(self, ):\n",
        "        super(RGB, self).__init__()\n",
        "        self.register_buffer('mean', torch.zeros(1, 3, 1, 1))\n",
        "        self.register_buffer('std', torch.ones(1, 3, 1, 1))\n",
        "        self.mean.data = torch.FloatTensor(self.IMAGE_RGB_MEAN).view(self.mean.shape)\n",
        "        self.std.data = torch.FloatTensor(self.IMAGE_RGB_STD).view(self.std.shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = (x - self.mean) / self.std\n",
        "        return x\n",
        "\n",
        "    \n",
        "    \n",
        "class Net(nn.Module):\n",
        "\t\n",
        "\t\tdef __init__(self,\n",
        "\t\t\t\t\t\t\t\tencoder=coat_lite_medium,\n",
        "\t\t\t\t\t\t\t\tdecoder=daformer_conv3x3,\n",
        "\t\t\t\t\t\t\t\tencoder_cfg={},\n",
        "\t\t\t\t\t\t\t\tdecoder_cfg={},\n",
        "\t\t\t\t\t\t\t\t):\n",
        "\t\t\t\tsuper(Net, self).__init__()\n",
        "\t\t\t\tdecoder_dim = decoder_cfg.get('decoder_dim', 320)\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.rgb = RGB()\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.encoder = encoder\n",
        "\t\t\t\tencoder_dim = self.encoder.embed_dims\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.decoder = decoder(\n",
        "\t\t\t\t\t\tencoder_dim=encoder_dim,\n",
        "\t\t\t\t\t\tdecoder_dim=decoder_dim,\n",
        "\t\t\t\t)\n",
        "\t\t\t\tself.logit = nn.Sequential(\n",
        "\t\t\t\t\t\tnn.Conv2d(decoder_dim, 1, kernel_size=1),\n",
        "\t\t\t\t\t\tnn.Upsample(scale_factor = 4, mode='bilinear', align_corners=False),\n",
        "\t\t\t\t)\n",
        "\t\t\n",
        "\t\tdef forward(self, batch):\n",
        "\t\t\t\n",
        "\t\t\t\tx = self.rgb(batch)\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\tB, C, H, W = x.shape\n",
        "\t\t\t\tencoder = self.encoder(x)\n",
        "\t\t\t\t\n",
        "\t\t\t\tlast, decoder = self.decoder(encoder)\n",
        "\t\t\t\tlogit = self.logit(last)\n",
        "\t\t\t\t\n",
        "\t\t\t\toutput = {}\n",
        "\t\t\t\tprobability_from_logit = torch.sigmoid(logit)\n",
        "\t\t\t\toutput['probability'] = probability_from_logit\n",
        "\t\t\t\t\n",
        "\t\t\t\treturn output\n",
        "\n",
        "\n",
        "def init_model():\n",
        "\t\t\"\"\"\n",
        "\t\tFunction used to initialize a CoaT model\n",
        "\t\t\"\"\"\n",
        "    encoder = coat_lite_medium()\n",
        "    checkpoint = './coat-pretrained/coat_lite_medium_a750cd63.pth' #pretrained weight available at the CoaT repository\n",
        "    checkpoint = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
        "    state_dict = checkpoint['model']\n",
        "    encoder.load_state_dict(state_dict,strict=False)\n",
        "    net = Net(encoder=encoder).cuda()\n",
        "    return net"
      ],
      "metadata": {
        "id": "9MGHTZHSsJW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definining the class for the custom loss and the evaluation metric:"
      ],
      "metadata": {
        "id": "qLdjD9HIAkFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss,self).__init__()\n",
        "        self.diceloss = smp.losses.DiceLoss(mode='binary')\n",
        "        self.binloss = smp.losses.SoftBCEWithLogitsLoss(reduction = 'mean' , smooth_factor = 0.1)\n",
        "        self.jaccardloss = smp.losses.JaccardLoss(mode='binary')\n",
        "\n",
        "    def forward(self, output, mask):\n",
        "        dice = self.diceloss(outputs, mask)\n",
        "        bce = self.binloss(outputs, mask)\n",
        "        jaccard = self.jaccardloss(outputs, mask)\n",
        "        loss = dice * 0.3 + jaccard * 0.7\n",
        "        return loss\n",
        "\n",
        "class DiceCoef(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, smooth=1.):\n",
        "        y_true = y_true.view(-1)\n",
        "        y_pred = y_pred.view(-1)\n",
        "        \n",
        "        y_pred = torch.round((y_pred - y_pred.min()) / (y_pred.max() - y_pred.min()))\n",
        "        \n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        dice = (2.0*intersection + smooth)/(y_true.sum() + y_pred.sum() + smooth)\n",
        "        \n",
        "        return dice"
      ],
      "metadata": {
        "id": "dpzsTBBxsJRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "FpTAgipFBevm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "train_scores=[]\n",
        "val_scores = []\n",
        "best_loss = 999\n",
        "best_score = 0\n",
        "\n",
        "model = init_model().to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam([\n",
        "    {'params': model.decoder.parameters(), 'lr': 5e-5}, \n",
        "    {'params': model.encoder.parameters(), 'lr': 5e-5},  \n",
        "])\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, \n",
        "                                          max_lr=1e-3,\n",
        "                                          epochs=EPOCHS, steps_per_epoch=len(train_loader))\n",
        "\n",
        "loss_func = CustomLoss()\n",
        "dice_coe = DiceCoef()\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "\n",
        "    # ------- Train ------- #\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    score = 0\n",
        "\n",
        "    for batch_idx, (img, mask, organ) in enumerate(train_loader):\n",
        "        \n",
        "        img = img.float().to(device=DEVICE)\n",
        "        mask = mask.float().to(device=DEVICE)\n",
        "        outputs = model(img)['probability']   \n",
        "\n",
        "        loss = loss_func(outputs, mask)\n",
        "        loss.backward()\n",
        "        \n",
        "        if ((batch_idx+1)*BATCH_SIZE % ACCUMULATION == 0) | ((batch_idx+1) == len(train_df)):\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "        train_loss += loss.detach()\n",
        "        score += dice_coe(outputs,mask).item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    score /= len(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "    train_scores.append(score)\n",
        "    print(f\"FOLD: {val_fold}, EPOCH: {epoch+1}, Train_Loss: {train_loss} , Dice Value: {score}\") #\n",
        "\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # ------ Validation ------ #\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        valid_loss = 0\n",
        "        val_score = 0\n",
        "\n",
        "        for i, (img, mask, organ) in enumerate(val_loader):\n",
        "\n",
        "            img = img.float().to(device=DEVICE)\n",
        "            mask = mask.float().to(device=DEVICE)\n",
        "            outputs = model(img)['probability']\n",
        "\n",
        "            loss = loss_func(outputs, mask)\n",
        "            valid_loss += loss.item()\n",
        "            val_score += dice_coe(outputs,mask).item()\n",
        "\n",
        "        valid_loss /= len(val_loader)\n",
        "        val_losses.append(valid_loss)\n",
        "\n",
        "        val_score /= len(val_loader)\n",
        "        val_scores.append(val_score)\n",
        "\n",
        "        print(f\"FOLD: {val_fold}, EPOCH: {epoch+1}, Valid_Loss: {valid_loss} , Valid Dice Value: {val_score}\") \n",
        "\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    if val_score > best_score:\n",
        "        best_score = val_score\n",
        "        torch.save(model.state_dict(), f\"./FOLD{fold}_best_score_epoch{epoch+1}.pth\")\n",
        "        print(f\"Saved model for best score : FOLD{fold}_best_score_epoch{epoch+1}.pth\")\n",
        "\n",
        "    if valid_loss < best_loss:\n",
        "        best_loss = valid_loss\n",
        "        torch.save(model.state_dict(), f\"./FOLD{fold}_best_loss_epoch{epoch+1}.pth\")\n",
        "        print(f\"Saved model for best loss : FOLD{fold}_best_loss_epoch{epoch+1}.pth\")    \n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        torch.save(model.state_dict(), f\"/kaggle/working/FOLD{fold}_epoch_{epoch+1}.pth\")\n",
        "        print(f\"Saved model for current epoch: FOLD{fold}_epoch_{epoch+1}.pth\")\n"
      ],
      "metadata": {
        "id": "TugDBkdaJVZx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}